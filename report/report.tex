\documentclass[a4paper, 11pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[pdftex]{hyperref}

% Lengths and indenting
\setlength{\textwidth}{16.5cm}
\setlength{\marginparwidth}{1.5cm}
\setlength{\parindent}{0cm}
\setlength{\parskip}{0.15cm}
\setlength{\textheight}{22cm}
\setlength{\oddsidemargin}{0cm}
\setlength{\evensidemargin}{\oddsidemargin}
\setlength{\topmargin}{0cm}
\setlength{\headheight}{0cm}
\setlength{\headsep}{0cm}

\renewcommand{\familydefault}{\sfdefault}

\title{Machine Learning 2014: Project 2 - Classification Report}
\author{lukasbi@student.ethz.ch\\ ajenal@student.ethz.ch\\ harhans@student.ethz.ch\\}
\date{\today}

\begin{document}
\maketitle

\section*{Experimental Protocol}
%Suppose that someone wants to reproduce your results. Briefly describe the steps used to obtain the
%predictions starting from the raw data set downloaded from the project website. Use the following
%sections to explain your methodology. Feel free to add graphs or screenshots if you think it's
%necessary. The report should contain a maximum of 2 pages.

\section{Tools}

For this exercise we used mainly Matlab, because most students in our group were familiarized with the software. The core functions used - such as $fitcsvm()$ and $kfoldLoss()$-were built-in functions of the MATLAB library. 
There was no other software used to get the results shown.


\section{Algorithm}
After reading the input files $training.csv$,$testing.csv$ and $validation.csv$, and separating the input from the output, we run a 10-fold cross validation over different kernels, namely:

\begin{table}[h]

\centering

\begin{tabular}{l l}
 
Linear Kernel: & $k(x,y) = x^Ty + c$ \\

Polynomial Kernel: & $k(x,y) = (\alpha x^Ty + c)^d$ \\

Gaussian (Radial Basis Function) Kernel: & $k(x,y) = exp(\frac{ ||x-y||^2}{2 \sigma ^2} )$ \\

MLP kernel: & $k(x,y) = tanh( k x^T_ix+\theta)$

\end{tabular}

\end{table}

The 10-fold cross validation runs with the method $fitcsvm$ to calculated the accumulation error. We chose the kernel with the smallest mean weighted classification error, to create our final support vector machine.
Using this SVM and the validation data, we get our predicted labels.

\section{Features}

Due to the fact that the features were already within a window of $[-1,1]$, we did not use any normalization/preprocessing on them. After several experiments, the best kernel in most cases was the Gaussian Radial Basis Kernel, followed by the linear kernel. Important to mention is that the evaluation with the linear kernel is much faster than one with a non-linear kernel (like rbf or mlp). This might be a factor to consider depending on the final application of the algorithm.

\section{Parameters}
How did you find the parameters of your model? (What parameters have you searched over, cross validation procedure, $\ldots$)

% outlier fraction with minimal error and boxconstraints, kernelscale with fminsearch
% Parameters for plynomial, rbf and mlp lernel?
\section{Lessons Learned} 

The different kernels delivered different results. It was expected to measure really high calculation times for polynomial kernels, but the poor results were quite surprising.
We did not try other algorithms outside the SVMs.
% e.g. linear and quadratic kernel ! %

\end{document}
